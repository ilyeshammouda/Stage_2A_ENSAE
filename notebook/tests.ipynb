{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import numpy as np\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining some useful functions\n",
    "\n",
    "def Rademacher_matrix(d,n):\n",
    "    \"\"\"\n",
    "    This fucntion generates a Rademacher matrix\n",
    "    \"\"\"\n",
    "    return np.random.choice([-1, 1], size=(d,n))\n",
    "\n",
    "\n",
    "\n",
    "def Rademacher_matrix_concatenated(d,n):\n",
    "    \"\"\"\n",
    "    This function generates a Rademacher matrix and add a line of ones\n",
    "    \"\"\"\n",
    "    Z=Rademacher_matrix(d,n)\n",
    "    Last_line_of_ones = np.ones((1, Z.shape[1]))\n",
    "    return (Z,np.concatenate((Z, Last_line_of_ones), axis=0))\n",
    "\n",
    "\n",
    "\n",
    "def Lasso_reg(Y_tilde,Z):\n",
    "    \"\"\"\n",
    "    This function gives the solution to the Lasso regression in a multivariate model\n",
    "    \"\"\"\n",
    "    lasso = linear_model.LassoCV(cv=5)\n",
    "    lasso.fit(Z,Y_tilde )\n",
    "    g = lasso.coef_\n",
    "    u=lasso.intercept_\n",
    "    return(g,u)\n",
    "\n",
    "\n",
    "def GradiantEstimate(x_t_vect:np.ndarray,d,n,delta,f):\n",
    "    \"\"\"\n",
    "    This function corresponds to the pseudo algorithme 1 defined in the paper\n",
    "    \"\"\"\n",
    "    Z=Rademacher_matrix(d,n)\n",
    "    y_t_vect=np.zeros(n)\n",
    "    for i in range(n):\n",
    "        z_i=Z[:, i]\n",
    "        y_t_vect[i] = f(x_t_vect+delta*z_i) #Construct the vector y_t:= f(x_t+delta*z_i)+noise. We suppose that f returns the true output plus noise\n",
    "    y_tilde=y_t_vect/delta\n",
    "    (g,u)=Lasso_reg(Y_tilde=y_tilde,Z=Z.T)\n",
    "    return(g,u)\n",
    "\n",
    "\n",
    "def random_vector_unit_spehre(d):\n",
    "    random_vector = np.random.normal(size=d)\n",
    "    return(random_vector/np.linalg.norm(random_vector))\n",
    "\n",
    "\n",
    "\n",
    "def BGD(delta,T_prime,f,d,y_t,S):\n",
    "        for t_prime in range (T_prime):\n",
    "             x_t=y_t+delta*random_vector_unit_spehre(d) #update x_t at each step where x_t=y_t+delta*u_t.\n",
    "             restriction_to_S=np.where(np.isin(x_t, S), x_t, 0) # Select the elements of x_t that are in S and set the coefficients of the remaining elements to 0.\n",
    "             f_ST=f(restriction_to_S) # Compute the fonction f where the input is the vector restricted to S\n",
    "             y_t=y_t-f_ST*(len(S)/delta)\n",
    "        return x_t\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Successive_selection_algo(T,eta,delta,f,s,B,d,n):\n",
    "    x_t_vect=np.zeros(d)\n",
    "    S_hat_t=[]\n",
    "    S_hat_t_minus_1=[1]\n",
    "    #chi_tilde={x for x in chi if np.linalg.norm(x,ord=1)<=B}\n",
    "    T_prime=int(T/2)\n",
    "    t=0\n",
    "    while len(S_hat_t)<s and t<s and len(S_hat_t)!=len(S_hat_t_minus_1): # setting  conditions to stop the while loop \n",
    "\n",
    "        S_hat_t_copy=S_hat_t.copy() # creating a copy of S_hat_t that will be used to update S_hat_t_minus_1\n",
    "        t=t+1\n",
    "        g_hat_t,u_t=GradiantEstimate(x_t_vect,d,n,delta,f) # Estimate the gradient g_t \n",
    "        right_set=[i for i in range(d) if abs(g_hat_t[i]) >= eta]\n",
    "        S_hat_t=S_hat_t_minus_1 + (right_set) # Thresholding\n",
    "        S_hat_t_minus_1=S_hat_t_copy # update S_hat_minus_1\n",
    "        x_t_minus_one=x_t_vect.copy() # Keep a copy of x_t to use it for the output \n",
    "        x_t_vect=BGD(T_prime=T_prime,f=f,d=d,y_t=x_t_vect,S=S_hat_t,delta=delta) # performe the finite difference algorithme that returns x_t\n",
    "    if len(S_hat_t)==s:\n",
    "         return(x_t_vect)\n",
    "    else:\n",
    "         return(x_t_minus_one)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions that will be used for testing \n",
    "def f_test(x_t,noise=1):#S le support \n",
    "    return(np.linalg.norm(x_t)+noise*np.random.normal(0,1,1))\n",
    "def vect_f_test(x_t, delta, d, n):\n",
    "    y_t_vecteur = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        y_t_vecteur[i] = f_test(x_t, delta, d)\n",
    "    y_t = f_test(x_t=x_t, delta=0, d=d, noise=0)\n",
    "    return y_t_vecteur, y_t\n",
    "def f_test_S(X_t,S,noise=1):\n",
    "    X_S=np.array([X_t[i] if i in S else 0 for i in range(len(X_t))])\n",
    "    return(np.linalg.norm(X_S)+np.sum(X_S))+noise*np.random.normal(0,1,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#precising the parameters \n",
    "d=100\n",
    "n=50\n",
    "delta=0.5\n",
    "lamda=0.1\n",
    "x_t=np.random.binomial(1, 1/2,size=(d,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_t,u_t=GradiantEstimate(x_t,d,n,delta,f_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The lasso estimator of g_t and u_t are:\n",
      "  g_t=[ 0.85584678 -0.         -0.27518014  0.         -0.92315559  0.\n",
      " -0.13270757 -0.49917827 -0.         -0.          1.27936878 -0.\n",
      "  0.          0.          0.         -0.          0.          0.04199\n",
      " -0.49251199 -0.          0.1991393  -0.42375978  0.         -0.\n",
      " -0.         -0.          0.          1.14341817  0.         -1.11363068\n",
      "  0.         -0.48977127 -0.         -0.46033951 -0.          0.\n",
      " -0.23029969  0.60316216  0.34387393  0.30580728 -0.20423971  0.\n",
      "  0.          0.14773199 -0.         -0.         -0.          0.\n",
      " -0.07978006 -0.30870114  0.         -0.09659295 -2.60461444  0.32942071\n",
      "  0.          0.          0.         -0.          1.25801597 -0.\n",
      " -0.         -0.97083662  1.30076493 -0.64672034  0.         -0.\n",
      " -0.43377556 -0.          0.         -0.          0.         -0.57633336\n",
      " -0.3184277  -0.04609787 -0.88207381  0.         -0.          0.\n",
      "  0.          0.          0.09776046  0.          0.         -1.0050212\n",
      "  0.06832417 -0.         -0.          0.76438894  1.42466696 -0.15302242\n",
      "  0.         -0.96858441  0.51035208  0.97861854  1.76187118  0.\n",
      " -0.          0.          0.         -0.        ] \n",
      " u_t=171.67928172986305 \n"
     ]
    }
   ],
   "source": [
    "print(f\" The lasso estimator of g_t and u_t are:\\n  g_t= {g_t} \\n u_t= {u_t} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ilyeshammouda/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e-02, tolerance: 5.737e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/ilyeshammouda/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.681e-02, tolerance: 7.286e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "Successive_selection_algo(T=100,eta=10,delta=2,f=f_test,s=10,B=2,d=d,n=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.02488653])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_vector = [1, 2, 3, 4, 5]\n",
    "indices = {1, 3}\n",
    "f_test_S(my_vector,indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
